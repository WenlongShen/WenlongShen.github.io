---
layout:     post
title:      "Deep Learning Book 学习笔记（17）"
subtitle:   "Monte Carlo Methods"
date:       2018-06-30
author:     "Wenlong Shen"
header-img: "img/bg/2018_3.jpg"
tags: 机器学习 读书笔记 2018
---

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=default"></script>

#### 采样和蒙特卡罗方法

当我们需要以较小的代价近似许多项的和或某个积分时，采样是一种很灵活的选择。机器学习中的许多重要工具都基于从某种分布中采样以及用这些样本对目标量做一个蒙特卡罗估计。

#### 重要采样

在蒙特卡罗方法中，对积分分解，确定积分中哪一部分作为概率分布以及哪一部分作为被积的函数是很关键的一步。如果考虑达到某给定精度所需要的样本数量，这个问题最优的采样函数对应所谓的最优重要采样。重要采样及其变种在机器学习的应用中扮演着重要的角色，包括深度学习算法。

#### 马尔可夫链蒙特卡罗方法

在许多实例中，我们希望采用蒙特卡罗方法，然而往往又不存在一种简单的方法可以直接从目标分布中精确采样或者一个好的（方差较小的）重要采样分布。这时可引入了一种称为马尔可夫链（Markov Chain）的数学工具，MCMC方法可以被广泛地应用在包含0概率状态的许多概率分布中。无论状态是连续的还是离散的，所有的马尔可夫链方法都包括了重复、随机地更新直到最后状态开始从均衡分布中采样。

#### 不同的峰值之间的混合挑战

使用MCMC方法的主要难点在于马尔可夫链的混合（Mixing）通常不理想。在理想情况下，从设计好的马尔可夫链中采出的连续样本之间是完全独立的，而且在$$x$$空间中，马尔可夫链会按概率大小访问许多不同区域。

然而，MCMC方法采出的样本可能会具有很强的相关性，尤其是在高维的情况下。我们把这种现象称为慢混合甚至混合失败。具有缓慢混合的MCMC方法可以被视为对能量函数无意地执行类似于带噪声的梯度下降的操作，或者说等价于相对于链的状态（被采样的随机变量）依据概率进行噪声爬坡。

在更实际的问题中，这种挑战更加艰巨因为在实际问题中我们不能仅仅关注在两个峰值之间的转移，更要关注在多个峰值之间的转移。如果由于峰值之间混合困难，而导致某几个这样的转移难以完成，那么得到一些可靠的覆盖大部分峰值的样本集合的计算代价是很高的，同时马尔可夫链收敛到它的平稳分布的过程也会非常缓慢。

尽管存在混合的难点，蒙特卡罗技术仍然是一个有用的工具，通常也是最好的可用工具。事实上，在遇到难以处理的无向模型中的配分函数时，蒙特卡罗方法仍然是最主要的工具。
